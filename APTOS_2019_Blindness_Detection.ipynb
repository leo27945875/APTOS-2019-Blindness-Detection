{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "colab": {
      "name": "APTOS_2019_Blindness_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLpFgi6IApsr"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import cv2\n",
        "import pickle\n",
        "from pprint import pprint\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "from utils import *\n",
        "from image_transform import *\n",
        "from loss_function import *\n",
        "from model import *\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import models\n",
        "from torchvision import transforms\n",
        "from ranger.ranger2020 import Ranger\n",
        "from pytorchcv.models import efficientnet\n",
        "\n",
        "plt.style.use(\"seaborn\")\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhwf6D71AptL"
      },
      "source": [
        "# 檔案設定:\n",
        "root = Root(r'C:\\AI\\Selected_Topics_in_Visual_Recognition_using_Deep_Learning\\Final')\n",
        "trainDir = root('train_images')\n",
        "testDir  = root('test_images' )\n",
        "extraDir = root('extra_images')\n",
        "modelDir = root('models')\n",
        "\n",
        "# 資料集設定:\n",
        "split = 0.8\n",
        "numClasses = 5\n",
        "\n",
        "# 訓練設定:\n",
        "vaild     = True\n",
        "device    = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "imgShape  = [300, 300]\n",
        "batchSize = 16\n",
        "imgMean   = [0.485, 0.456, 0.406]\n",
        "imgStd    = [0.229, 0.224, 0.225]\n",
        "lr        = 1e-5\n",
        "\n",
        "# 測試設定:\n",
        "threshold = [0.5, 1.5, 2.5, 3.5]\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3W8csNCAptP"
      },
      "source": [
        "trainDF, validDF = pd.read_csv(root('train.csv'))[['id_code', 'diagnosis']], pd.read_csv(root('valid.csv'))[['id_code', 'diagnosis']]\n",
        "allDF = pd.concat([trainDF, validDF], ignore_index=True)\n",
        "\n",
        "trainTransforms = transforms.Compose([\n",
        "    CropImageFromGray(),\n",
        "    ClearImage(),\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize(imgShape),\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "    transforms.RandomVerticalFlip(0.5),\n",
        "    transforms.RandomAffine(180, shear=0.2, resample=Image.BILINEAR),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(imgMean, imgStd)\n",
        "])\n",
        "\n",
        "validTransforms = transforms.Compose([\n",
        "    CropImageFromGray(),\n",
        "    ClearImage(),\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize(imgShape),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(imgMean, imgStd)\n",
        "])\n",
        "\n",
        "trainDS = ImageDataset(trainDF, True , 'id_code', 'diagnosis', transform=trainTransforms, imageDir=trainDir)\n",
        "validDS = ImageDataset(validDF, True , 'id_code', 'diagnosis', transform=validTransforms, imageDir=trainDir)\n",
        "\n",
        "trainDL = DataLoader(trainDS, batch_size=batchSize, shuffle=True , num_workers=12)\n",
        "validDL = DataLoader(validDS, batch_size=batchSize, shuffle=False, num_workers=12)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQ0B_8mEzaDz",
        "outputId": "ef91209d-241a-4390-a981-5d93eae2698d"
      },
      "source": [
        "class GeM(nn.Module):\n",
        "    def __init__(self, p=3, eps=1e-6):\n",
        "        super(GeM,self).__init__()\n",
        "        self.p = Parameter(torch.ones(1)*p)\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.gem(x, p=self.p, eps=self.eps)  \n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n",
        "    \n",
        "    @staticmethod\n",
        "    def gem(x, p=3, eps=1e-6):\n",
        "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
        "\n",
        "\n",
        "class Detector(nn.Module):\n",
        "    def __init__(self, numClasses, threshold):\n",
        "        super(Detector, self).__init__()\n",
        "        self.numClasses = numClasses\n",
        "        self.threshold = torch.tensor([(2 * t - (numClasses - 1)) / (numClasses - 1) for t in threshold])\n",
        "\n",
        "        net = efficientnet.efficientnet_b2c(pretrained=True)\n",
        "        net.features.final_pool = GeM()\n",
        "        inputDim = net.output.fc.in_features\n",
        "        self.cnn = net.features\n",
        "        self.flat = nn.Flatten()\n",
        "        self.drop = nn.Dropout(p=0.2)\n",
        "        self.cls = nn.Sequential(\n",
        "            nn.Linear(inputDim, numClasses, bias=False)\n",
        "        )\n",
        "        self.reg = nn.Sequential(\n",
        "            nn.Linear(inputDim, 1, bias=False)\n",
        "        )\n",
        "\n",
        "        del net\n",
        "    \n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.drop(self.flat(self.cnn(x)))\n",
        "        c = self.cls(h)\n",
        "        r = self.reg(h)\n",
        "        return c, r\n",
        "    \n",
        "\n",
        "    def ConvertRegressionToClass(self, r):\n",
        "        r = r.detach().to(self.threshold.device)\n",
        "        return torch.sum(r > self.threshold, dim=1)\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swv8hKdfBV3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37be1184-6136-4cc0-bc07-160f0304e906"
      },
      "source": [
        "# Model: ---------------------------------------------------------------------\n",
        "model = Detector(numClasses, threshold)\n",
        "model.requires_grad_()\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss functions: -----------------------------------------------------------\n",
        "criterion1 = nn.CrossEntropyLoss().to(device)\n",
        "criterion2 = nn.MSELoss().to(device)\n",
        "\n",
        "# Optimizer: -----------------------------------------------------------------\n",
        "optimizer = Ranger(model.parameters(), weight_decay=1e-4, lr=lr)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=100, T_mult=3, eta_min=1e-6)\n",
        "\n",
        "# Load state: ---------------------------------------------------------------\n",
        "# _, model, optimizer, scheduler = LoadState(model, \n",
        "#                                            optimizer, \n",
        "#                                            scheduler, \n",
        "#                                            os.path.join(modelDir, 'state10_epoch50_trainRegAcc=0.8_trainClsAcc=0.9138.pth'))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranger optimizer loaded. \nGradient Centralization usage = True\nGC applied to both conv and fc layers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZlrIpZfAptQ",
        "outputId": "e1f8f5ce-3e6f-4344-e2a0-b7441a296871"
      },
      "source": [
        "# Validation process:\n",
        "def Validate(model, validDL, device):\n",
        "    clsAcc = 0.\n",
        "    regAcc = 0.\n",
        "    num = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in validDL:\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            c, r = model(imgs)\n",
        "            clsAcc += GetAccuracy(c, labels).item()\n",
        "            regAcc += GetAccuracy(model.ConvertRegressionToClass(r), labels).item()\n",
        "            num += 1\n",
        "\n",
        "        clsAcc /= num\n",
        "        regAcc /= num\n",
        "    \n",
        "    return clsAcc, regAcc\n",
        "\n",
        "\n",
        "# Training process:\n",
        "save = True\n",
        "startEpoch = 1\n",
        "endEpoch   = 50\n",
        "numBatch = len(trainDS) // batchSize + 1\n",
        "maxValidAcc = 0.\n",
        "for epoch in range(startEpoch, endEpoch + 1):\n",
        "    trainClsAccuracy = 0.\n",
        "    trainRegAccuracy = 0.\n",
        "    for i, (imgs, labels) in enumerate(trainDL):\n",
        "        # Inputs & targets:\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        target = ((2 * labels - (numClasses - 1)) / (numClasses - 1)).view(-1, 1).to(device).detach()\n",
        "\n",
        "        # Train model:\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "            \n",
        "        c, r = model(imgs)\n",
        "        loss = 0.25 * criterion1(c, labels) + criterion2(r, target)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        trainClsAccuracy += GetAccuracy(c, labels).item()\n",
        "        trainRegAccuracy += GetAccuracy(model.ConvertRegressionToClass(r), labels).item()\n",
        "        sys.stdout.write(f\"\\r|Epoch {epoch}/{endEpoch}|Batch {i + 1}/{numBatch}| => Train Classifier Acc = {round(trainClsAccuracy / (i + 1), 4)}, Train Regressor Acc = {round(trainRegAccuracy / (i + 1), 4)}\")\n",
        "\n",
        "    # Test model:\n",
        "    if epoch % 1 == 0 and vaild:\n",
        "        validClsAccuracy, validRegAccuracy = Validate(model, validDL, device)\n",
        "        print(f\", Valid Classifier Acc = {round(validClsAccuracy, 4)}, Valid Regressor Acc = {round(validRegAccuracy, 4)}\")\n",
        "    else:\n",
        "        print(\" \")\n",
        "    \n",
        "    if save:\n",
        "        name = f'state11_epoch{epoch}_trainRegAcc={round(trainRegAccuracy / numBatch, 4)}_trainClsAcc={round(trainClsAccuracy / numBatch, 4)}.pth'\n",
        "        path = os.path.join(modelDir, name)\n",
        "        SaveState(model, optimizer, scheduler, epoch, path)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|Epoch 1/50|Batch 206/206| => Train Classifier Acc = 0.5264, Train Regressor Acc = 0.2932, Valid Classifier Acc = 0.6183, Valid Regressor Acc = 0.4058\n",
            "|Epoch 2/50|Batch 206/206| => Train Classifier Acc = 0.6814, Train Regressor Acc = 0.4767, Valid Classifier Acc = 0.6728, Valid Regressor Acc = 0.4303\n",
            "|Epoch 3/50|Batch 206/206| => Train Classifier Acc = 0.7181, Train Regressor Acc = 0.5612, Valid Classifier Acc = 0.6839, Valid Regressor Acc = 0.6103\n",
            "|Epoch 4/50|Batch 206/206| => Train Classifier Acc = 0.7323, Train Regressor Acc = 0.6279, Valid Classifier Acc = 0.6812, Valid Regressor Acc = 0.6565\n",
            "|Epoch 5/50|Batch 206/206| => Train Classifier Acc = 0.7396, Train Regressor Acc = 0.6325, Valid Classifier Acc = 0.6893, Valid Regressor Acc = 0.635\n",
            "|Epoch 6/50|Batch 206/206| => Train Classifier Acc = 0.7399, Train Regressor Acc = 0.634, Valid Classifier Acc = 0.6812, Valid Regressor Acc = 0.6621\n",
            "|Epoch 7/50|Batch 206/206| => Train Classifier Acc = 0.7433, Train Regressor Acc = 0.6324, Valid Classifier Acc = 0.692, Valid Regressor Acc = 0.6404\n",
            "|Epoch 8/50|Batch 206/206| => Train Classifier Acc = 0.7538, Train Regressor Acc = 0.6443, Valid Classifier Acc = 0.7002, Valid Regressor Acc = 0.6812\n",
            "|Epoch 9/50|Batch 206/206| => Train Classifier Acc = 0.7588, Train Regressor Acc = 0.6536, Valid Classifier Acc = 0.7192, Valid Regressor Acc = 0.6621\n",
            "|Epoch 10/50|Batch 206/206| => Train Classifier Acc = 0.7699, Train Regressor Acc = 0.6583, Valid Classifier Acc = 0.7219, Valid Regressor Acc = 0.6813\n",
            "|Epoch 11/50|Batch 206/206| => Train Classifier Acc = 0.7775, Train Regressor Acc = 0.6616, Valid Classifier Acc = 0.7464, Valid Regressor Acc = 0.6786\n",
            "|Epoch 12/50|Batch 206/206| => Train Classifier Acc = 0.7928, Train Regressor Acc = 0.6656, Valid Classifier Acc = 0.7438, Valid Regressor Acc = 0.6868\n",
            "|Epoch 13/50|Batch 206/206| => Train Classifier Acc = 0.7851, Train Regressor Acc = 0.6686, Valid Classifier Acc = 0.7547, Valid Regressor Acc = 0.7116\n",
            "|Epoch 14/50|Batch 206/206| => Train Classifier Acc = 0.8063, Train Regressor Acc = 0.678, Valid Classifier Acc = 0.752, Valid Regressor Acc = 0.6897\n",
            "|Epoch 15/50|Batch 206/206| => Train Classifier Acc = 0.8006, Train Regressor Acc = 0.7053, Valid Classifier Acc = 0.7683, Valid Regressor Acc = 0.6841\n",
            "|Epoch 16/50|Batch 206/206| => Train Classifier Acc = 0.8033, Train Regressor Acc = 0.6786, Valid Classifier Acc = 0.7683, Valid Regressor Acc = 0.6487\n",
            "|Epoch 17/50|Batch 15/206| => Train Classifier Acc = 0.8458, Train Regressor Acc = 0.725"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-11-6c0c1d4ef307>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;31m# Train model:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[1;34m(self, set_to_none)\u001b[0m\n\u001b[0;32m    190\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m                             \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m                         \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}